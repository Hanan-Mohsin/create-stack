# Use the latest 2.1 version of CircleCI pipeline process engine. See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1
# Use a package of configuration called an orb.
orbs:
  aws-cli: circleci/aws-cli@3.1.4
# Orchestrate or schedule a set of jobs
commands:
  print_pipeline_id:
    description: "Print the circle workflow id"
    parameters:
      circle_id:
        type: string
    steps:
      - run: echo << parameters.circle_id >>

  destroy_environment:
    steps:
      - run:
          name: Destroy environment
          # ${CIRCLE_WORKFLOW_ID} is a Built-in environment variable 
          # ${CIRCLE_WORKFLOW_ID:0:5} takes the first 5 chars of the variable CIRCLE_CI_WORKFLOW_ID 
          when: on_fail
          command: |
            aws cloudformation delete-stack --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} --region us-east-1
jobs:
  create_infrastructure: 
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      # - aws-cli/setup:
      #     aws-access-key-id: ACCESS_KEY
      #     aws-secret-access-key: SECRET_KEY
      #     aws-region: REGION
      - run:
          name: Create Cloudformation Stack
          command: aws cloudformation deploy --template-file template.yml --stack-name myStack-${CIRCLE_WORKFLOW_ID:0:5} --region us-east-1

  # Exercise: Config and Deployment
  configure_infrastructure: 
    docker:
      - image: python:3.10-alpine
    steps:
      - checkout
      - add_ssh_keys:
              fingerprints: ["dd:a0:f5:2c:b6:9f:ea:ff:0c:98:58:82:43:6b:88:31"] 
      - run:
          name: Install Ansible
          command: apk add --update ansible
      - run:
          name: Ansible version
          command: ansible --version
      - run:
          name: Run Playbook and Configure server
          command: ansible-playbook -i inventory.txt main.yml

  smoke_test:
    docker:
      - image: amazon/aws-cli
      - image: alpine:latest
    steps:
      - checkout
      - run: apk add --update curl
      # - aws-cli/setup:
      #     aws-access-key-id: ACCESS_KEY
      #     aws-secret-access-key: SECRET_KEY
      #     aws-region: REGION
      - run:
          name: smoke test
          command: |
            URL="https://blog.udacihjhjty.com/"
            # Test if website exists
            if curl -s --head ${URL} 
            then
              return 0
            else
              return 1
            fi
      - destroy_environment  

    # Executes the bucket.yml - Deploy an S3 bucket, and interface with that bucket to synchronize the files between local and the bucket.
  # Note that the `--parameter-overrides` let you specify a value that override parameter value in the bucket.yml template file.
  create_and_deploy_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute bucket.yml - Create Cloudformation Stack
          command: |
            aws cloudformation deploy \
            --template-file bucket.yml \
            --stack-name stack-create-bucket-${CIRCLE_WORKFLOW_ID:0:7} \
            --parameter-overrides MyBucketName="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

  get_last_deployment_id:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - run:
          name: Fetch and save the old pipeline ID (bucket name) responsible for the last release.
          command: |
            aws cloudformation \
            list-exports --query "Exports[?Name==\`PipelineID\`].Value" \
            --no-paginate --output text > ~/textfile.txt
      - persist_to_workspace:
          root: ~/
          paths: 
            - textfile.txt

  promote_to_production:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run:
          name: Execute cloudfront.yml
          command: |
            aws cloudformation deploy \
            --template-file cloudfront.yml \
            --stack-name production-distro2 \
            --parameter-overrides PipelineID="mybucket-${CIRCLE_WORKFLOW_ID:0:7}"

  clean_up_old_front_end:
    docker:
      - image: amazon/aws-cli
    steps:
      - checkout
      - run: yum install -y tar gzip
      - attach_workspace:
          at: ~/
      - run:
          name: Destroy the previous production version's S3 bucket and CloudFormation stack. 
          # Use $OldBucketID environment variable or mybucket644752792305 below.
          # Similarly, you can create and use $OldStackID environment variable in place of production-distro 
          command: |
            export OldBucketID=$(cat ~/textfile.txt)
            aws s3 rm "s3://${OldBucketID}" --recursive

 
workflows:
  # Name the workflow "welcome"
  welcome:
    # Run the welcome/run job in its own container
    jobs:
      - create_and_deploy_front_end
      - promote_to_production:
          requires: 
            - create_and_deploy_front_end
      - get_last_deployment_id
      - clean_up_old_front_end:
          requires:
            - get_last_deployment_id
            - promote_to_production
    